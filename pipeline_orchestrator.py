import time
import schedule
import subprocess
import psycopg2
import pandas as pd
import numpy as np
import logging
import json
import os
import warnings
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score
import joblib
from contextlib import contextmanager
import threading

warnings.filterwarnings('ignore')

# Configure comprehensive logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    handlers=[
        logging.FileHandler(f'cmp_quality_system_{datetime.now().strftime("%Y%m%d")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SystemStatus(Enum):
    HEALTHY = "HEALTHY"
    WARNING = "WARNING" 
    CRITICAL = "CRITICAL"
    DEGRADED = "DEGRADED"
    MAINTENANCE = "MAINTENANCE"

class RiskLevel(Enum):
    LOW = "ðŸŸ¢ LOW"
    ELEVATED = "ðŸŸ  ELEVATED"
    MEDIUM = "ðŸŸ¡ MEDIUM"
    HIGH = "ðŸ”´ HIGH"
    CRITICAL = "âš« CRITICAL"

@dataclass
class QualityThresholds:
    """Production quality parameter thresholds"""
    thickness_min: float = 0.5
    thickness_max: float = 1.5
    pressure_min: float = 1.0
    pressure_max: float = 10.0
    temperature_min: float = 15.0
    temperature_max: float = 40.0
    rotation_speed_min: float = 30.0
    rotation_speed_max: float = 250.0
    fault_rate_warning: float = 15.0  # %
    fault_rate_critical: float = 25.0  # %
    data_freshness_minutes: int = 30
    min_hourly_records: int = 5

@dataclass
class ModelConfiguration:
    """ML model configuration"""
    retrain_frequency_hours: int = 4
    min_training_samples: int = 100
    min_accuracy_threshold: float = 0.75
    model_drift_threshold: float = 0.05
    cross_validation_folds: int = 5
    feature_importance_threshold: float = 0.01
    prediction_confidence_threshold: float = 0.6

@dataclass
class SystemConfiguration:
    """System-wide configuration"""
    db_config: Dict[str, str]
    quality_thresholds: QualityThresholds
    model_config: ModelConfiguration
    cost_per_defect: float = 150.0
    cost_per_early_discard: float = 25.0
    enable_email_alerts: bool = False
    email_config: Optional[Dict[str, str]] = None
    backup_frequency_hours: int = 24
    max_log_retention_days: int = 30

class DataQualityValidator:
    """Comprehensive data quality validation"""
    
    def __init__(self, thresholds: QualityThresholds):
        self.thresholds = thresholds
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
    
    def validate_sensor_data(self, data: Dict[str, float]) -> Tuple[bool, List[str]]:
        """Validate individual sensor readings"""
        issues = []
        
        # Range validation
        if not (self.thresholds.thickness_min <= data.get('thickness', 0) <= self.thresholds.thickness_max):
            issues.append(f"Thickness {data.get('thickness')} outside range [{self.thresholds.thickness_min}, {self.thresholds.thickness_max}]")
        
        if not (self.thresholds.pressure_min <= data.get('pressure', 0) <= self.thresholds.pressure_max):
            issues.append(f"Pressure {data.get('pressure')} outside range [{self.thresholds.pressure_min}, {self.thresholds.pressure_max}]")
        
        if not (self.thresholds.temperature_min <= data.get('temperature', 0) <= self.thresholds.temperature_max):
            issues.append(f"Temperature {data.get('temperature')} outside range [{self.thresholds.temperature_min}, {self.thresholds.temperature_max}]")
        
        if not (self.thresholds.rotation_speed_min <= data.get('rotation_speed', 0) <= self.thresholds.rotation_speed_max):
            issues.append(f"Rotation speed {data.get('rotation_speed')} outside range [{self.thresholds.rotation_speed_min}, {self.thresholds.rotation_speed_max}]")
        
        # Data completeness
        required_fields = ['thickness', 'pressure', 'temperature', 'rotation_speed']
        for field in required_fields:
            if field not in data or data[field] is None or np.isnan(data[field]):
                issues.append(f"Missing or invalid {field}")
        
        return len(issues) == 0, issues
    
    def validate_batch_data(self, df: pd.DataFrame) -> Tuple[bool, Dict[str, Any]]:
        """Validate batch of production data"""
        validation_report = {
            'total_records': len(df),
            'valid_records': 0,
            'invalid_records': 0,
            'missing_values': {},
            'outliers': {},
            'statistical_drift': {},
            'issues': []
        }
        
        if len(df) == 0:
            validation_report['issues'].append("Empty dataset")
            return False, validation_report
        
        # Check for missing values
        for column in ['thickness', 'pressure', 'temperature', 'rotation_speed']:
            if column in df.columns:
                missing_count = df[column].isnull().sum()
                validation_report['missing_values'][column] = missing_count
                if missing_count > 0:
                    validation_report['issues'].append(f"{column}: {missing_count} missing values")
        
        # Statistical outlier detection
        for column in ['thickness', 'pressure', 'temperature', 'rotation_speed']:
            if column in df.columns and not df[column].empty:
                Q1 = df[column].quantile(0.25)
                Q3 = df[column].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
                outlier_count = len(outliers)
                validation_report['outliers'][column] = outlier_count
                if outlier_count > len(df) * 0.05:  # More than 5% outliers
                    validation_report['issues'].append(f"{column}: {outlier_count} outliers detected")
        
        # Data freshness check
        if 'created_at' in df.columns:
            latest_record = df['created_at'].max()
            if isinstance(latest_record, str):
                latest_record = pd.to_datetime(latest_record)
            
            minutes_old = (datetime.now() - latest_record).total_seconds() / 60
            if minutes_old > self.thresholds.data_freshness_minutes:
                validation_report['issues'].append(f"Data is {minutes_old:.1f} minutes old (threshold: {self.thresholds.data_freshness_minutes})")
        
        # Record validation summary
        validation_report['valid_records'] = len(df) - sum(validation_report['missing_values'].values())
        validation_report['invalid_records'] = sum(validation_report['missing_values'].values())
        
        is_valid = len(validation_report['issues']) == 0
        return is_valid, validation_report

class DatabaseManager:
    """Robust database connection management with retry logic"""
    
    def __init__(self, db_config: Dict[str, str]):
        self.db_config = db_config
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        self.max_retries = 3
        self.retry_delay = 5  # seconds
    
    @contextmanager
    def get_connection(self):
        """Get database connection with automatic retry and cleanup"""
        conn = None
        for attempt in range(self.max_retries):
            try:
                conn = psycopg2.connect(**self.db_config)
                yield conn
                conn.commit()
                break
            except psycopg2.OperationalError as e:
                self.logger.warning(f"Database connection attempt {attempt + 1} failed: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                else:
                    self.logger.error("All database connection attempts failed")
                    raise
            except Exception as e:
                self.logger.error(f"Unexpected database error: {e}")
                if conn:
                    conn.rollback()
                raise
            finally:
                if conn:
                    conn.close()
    
    def execute_query(self, query: str, params: Optional[Tuple] = None) -> Optional[pd.DataFrame]:
        """Execute query with error handling"""
        try:
            with self.get_connection() as conn:
                if params:
                    return pd.read_sql(query, conn, params=params)
                else:
                    return pd.read_sql(query, conn)
        except Exception as e:
            self.logger.error(f"Query execution failed: {query[:100]}..., Error: {e}")
            return None
    
    def execute_command(self, command: str, params: Optional[Tuple] = None) -> bool:
        """Execute command (INSERT, UPDATE, DELETE) with error handling"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                if params:
                    cursor.execute(command, params)
                else:
                    cursor.execute(command)
                cursor.close()
                return True
        except Exception as e:
            self.logger.error(f"Command execution failed: {command[:100]}..., Error: {e}")
            return False

class ModelManager:
    """Advanced ML model management with drift detection and automated retraining"""
    
    def __init__(self, config: ModelConfiguration, db_manager: DatabaseManager):
        self.config = config
        self.db_manager = db_manager
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        self.model = None
        self.scaler = None
        self.feature_columns = ['thickness', 'pressure', 'temperature', 'rotation_speed']
        self.last_training_time = None
        self.model_version = "1.0.0"
        self.model_accuracy = 0.0
        self.baseline_performance = None
        
        # Initialize model storage tables
        self._initialize_model_tables()
    
    def _initialize_model_tables(self):
        """Initialize database tables for model management"""
        tables_sql = [
            """
            CREATE TABLE IF NOT EXISTS cmp_data.model_training_log (
                id SERIAL PRIMARY KEY,
                model_version VARCHAR(20),
                accuracy DECIMAL(8,6),
                precision_score DECIMAL(8,6),
                recall_score DECIMAL(8,6),
                f1_score DECIMAL(8,6),
                auc_score DECIMAL(8,6),
                train_samples INTEGER,
                test_samples INTEGER,
                cross_val_score DECIMAL(8,6),
                feature_importance JSONB,
                training_duration_seconds INTEGER,
                training_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                model_file_path VARCHAR(255),
                scaler_file_path VARCHAR(255),
                validation_report JSONB
            );
            """,
            """
            CREATE TABLE IF NOT EXISTS cmp_data.model_performance_monitoring (
                id SERIAL PRIMARY KEY,
                model_version VARCHAR(20),
                prediction_accuracy DECIMAL(8,6),
                drift_score DECIMAL(8,6),
                data_quality_score DECIMAL(8,6),
                total_predictions INTEGER,
                correct_predictions INTEGER,
                monitoring_period_start TIMESTAMP,
                monitoring_period_end TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            """
            CREATE TABLE IF NOT EXISTS cmp_data.data_quality_reports (
                id SERIAL PRIMARY KEY,
                report_type VARCHAR(50),
                total_records INTEGER,
                valid_records INTEGER,
                invalid_records INTEGER,
                missing_values JSONB,
                outliers JSONB,
                validation_issues JSONB,
                quality_score DECIMAL(5,2),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """
        ]
        
        for sql in tables_sql:
            self.db_manager.execute_command(sql)
    
    def should_retrain_model(self) -> Tuple[bool, str]:
        """Determine if model should be retrained"""
        if self.model is None:
            return True, "No model loaded"
        
        if self.last_training_time is None:
            return True, "No training history"
        
        # Time-based retraining
        hours_since_training = (datetime.now() - self.last_training_time).total_seconds() / 3600
        if hours_since_training >= self.config.retrain_frequency_hours:
            return True, f"Scheduled retraining ({hours_since_training:.1f} hours since last training)"
        
        # Performance-based retraining
        if self.model_accuracy < self.config.min_accuracy_threshold:
            return True, f"Model accuracy {self.model_accuracy:.3f} below threshold {self.config.min_accuracy_threshold}"
        
        return False, "Model is current"
    
    def get_training_data(self, hours_back: int = 72) -> Optional[pd.DataFrame]:
        """Get high-quality training data with validation"""
        try:
            query = f"""
            SELECT thickness, pressure, temperature, rotation_speed, is_faulty, created_at
            FROM cmp_data.pad_quality
            WHERE created_at >= NOW() - INTERVAL '{hours_back} hours'
            AND thickness IS NOT NULL 
            AND pressure IS NOT NULL 
            AND temperature IS NOT NULL 
            AND rotation_speed IS NOT NULL
            AND thickness BETWEEN %s AND %s
            AND pressure BETWEEN %s AND %s
            AND temperature BETWEEN %s AND %s
            AND rotation_speed BETWEEN %s AND %s
            ORDER BY created_at DESC
            """
            
            thresholds = QualityThresholds()
            params = (
                thresholds.thickness_min, thresholds.thickness_max,
                thresholds.pressure_min, thresholds.pressure_max,
                thresholds.temperature_min, thresholds.temperature_max,
                thresholds.rotation_speed_min, thresholds.rotation_speed_max
            )
            
            df = self.db_manager.execute_query(query, params)
            
            if df is not None:
                self.logger.info(f"Retrieved {len(df)} valid training records from last {hours_back} hours")
            
            return df
            
        except Exception as e:
            self.logger.error(f"Error getting training data: {e}")
            return None
    
    def train_model(self) -> Tuple[bool, Dict[str, Any]]:
        """Train ML model with comprehensive validation and monitoring"""
        start_time = time.time()
        training_report = {
            'success': False,
            'accuracy': 0.0,
            'training_samples': 0,
            'test_samples': 0,
            'feature_importance': {},
            'cross_validation_score': 0.0,
            'training_duration': 0,
            'issues': []
        }
        
        try:
            self.logger.info("Starting model training...")
            
            # Get training data
            df = self.get_training_data()
            
            if df is None or len(df) < self.config.min_training_samples:
                training_report['issues'].append(
                    f"Insufficient training data: {len(df) if df is not None else 0} < {self.config.min_training_samples}"
                )
                return False, training_report
            
            # Prepare features and target
            X = df[self.feature_columns]
            y = df['is_faulty']
            
            # Check class balance
            class_counts = y.value_counts()
            minority_class_ratio = min(class_counts) / len(y)
            
            if minority_class_ratio < 0.1:  # Less than 10% minority class
                training_report['issues'].append(f"Severe class imbalance: {minority_class_ratio:.1%} minority class")
                self.logger.warning(f"Class imbalance detected: {class_counts.to_dict()}")
            
            # Split data with stratification
            try:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42, stratify=y
                )
            except ValueError:
                # Fallback for severe imbalance
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=0.2, random_state=42
                )
                training_report['issues'].append("Could not stratify due to class imbalance")
            
            # Feature scaling with robust scaler (handles outliers better)
            self.scaler = RobustScaler()
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
            
            # Train model with hyperparameter optimization
            self.model = RandomForestClassifier(
                n_estimators=200,  # More trees for better performance
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                class_weight='balanced',
                n_jobs=-1  # Use all CPU cores
            )
            
            self.model.fit(X_train_scaled, y_train)
            
            # Comprehensive evaluation
            y_pred = self.model.predict(X_test_scaled)
            y_pred_proba = self.model.predict_proba(X_test_scaled)
            
            # Calculate metrics
            accuracy = accuracy_score(y_test, y_pred)
            
            # Cross-validation for robust performance estimate
            cv_scores = cross_val_score(self.model, X_train_scaled, y_train, 
                                      cv=self.config.cross_validation_folds, scoring='accuracy')
            cv_mean = cv_scores.mean()
            
            # Feature importance analysis
            feature_importance = dict(zip(self.feature_columns, self.model.feature_importances_))
            
            # Update model metadata
            self.model_accuracy = accuracy
            self.last_training_time = datetime.now()
            self.model_version = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Training report
            training_report.update({
                'success': True,
                'accuracy': accuracy,
                'training_samples': len(X_train),
                'test_samples': len(X_test),
                'feature_importance': feature_importance,
                'cross_validation_score': cv_mean,
                'training_duration': int(time.time() - start_time)
            })
            
            # Save model
            model_path = f'models/cmp_model_{self.model_version}.pkl'
            scaler_path = f'models/cmp_scaler_{self.model_version}.pkl'
            
            os.makedirs('models', exist_ok=True)
            joblib.dump(self.model, model_path)
            joblib.dump(self.scaler, scaler_path)
            
            # Also save as latest
            joblib.dump(self.model, 'defect_prediction_model.pkl')
            joblib.dump(self.scaler, 'defect_scaler.pkl')
            
            # Log training to database
            self._log_training_results(training_report, model_path, scaler_path)
            
            self.logger.info(f"Model training completed successfully - Accuracy: {accuracy:.3f}, CV: {cv_mean:.3f}")
            
            return True, training_report
            
        except Exception as e:
            training_report['issues'].append(f"Training failed: {str(e)}")
            self.logger.error(f"Model training failed: {e}")
            return False, training_report
    
    def _log_training_results(self, training_report: Dict, model_path: str, scaler_path: str):
        """Log training results to database"""
        try:
            sql = """
            INSERT INTO cmp_data.model_training_log 
            (model_version, accuracy, train_samples, test_samples, cross_val_score, 
             feature_importance, training_duration_seconds, model_file_path, scaler_file_path)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            
            params = (
                self.model_version,
                training_report['accuracy'],
                training_report['training_samples'],
                training_report['test_samples'],
                training_report['cross_validation_score'],
                json.dumps(training_report['feature_importance']),
                training_report['training_duration'],
                model_path,
                scaler_path
            )
            
            self.db_manager.execute_command(sql, params)
            
        except Exception as e:
            self.logger.error(f"Failed to log training results: {e}")
    
    def predict_defect_probability(self, thickness: float, pressure: float, 
                                 temperature: float, rotation_speed: float) -> Tuple[Optional[bool], Optional[float], str]:
        """Predict defect probability with confidence assessment"""
        try:
            if self.model is None or self.scaler is None:
                return None, None, "Model not loaded"
            
            # Validate input data
            validator = DataQualityValidator(QualityThresholds())
            data = {
                'thickness': thickness,
                'pressure': pressure,
                'temperature': temperature,
                'rotation_speed': rotation_speed
            }
            
            is_valid, issues = validator.validate_sensor_data(data)
            if not is_valid:
                return None, None, f"Invalid input data: {', '.join(issues)}"
            
            # Prepare input
            input_data = np.array([[thickness, pressure, temperature, rotation_speed]])
            input_scaled = self.scaler.transform(input_data)
            
            # Get prediction and probability
            prediction = self.model.predict(input_scaled)[0]
            probabilities = self.model.predict_proba(input_scaled)[0]
            
            # Get defect probability (probability of class 1 = defective)
            defect_prob = probabilities[1] if len(probabilities) > 1 else 0.0
            
            # Confidence assessment based on prediction margin
            confidence = abs(probabilities[1] - probabilities[0]) if len(probabilities) > 1 else 0.0
            confidence_msg = ""
            
            if confidence < 0.3:
                confidence_msg = "Low confidence prediction"
            elif confidence > 0.7:
                confidence_msg = "High confidence prediction"
            else:
                confidence_msg = "Moderate confidence prediction"
            
            return bool(prediction), defect_prob, confidence_msg
            
        except Exception as e:
            self.logger.error(f"Prediction failed: {e}")
            return None, None, f"Prediction error: {str(e)}"

class AlertManager:
    """Industry-grade alert management system"""
    
    def __init__(self, config: SystemConfiguration):
        self.config = config
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        self.alert_history = []
        self.max_alerts_per_hour = 10  # Rate limiting
    
    def send_alert(self, level: str, title: str, message: str, data: Optional[Dict] = None):
        """Send alert with rate limiting and logging"""
        try:
            # Rate limiting
            current_time = datetime.now()
            recent_alerts = [a for a in self.alert_history 
                           if (current_time - a['timestamp']).total_seconds() < 3600]
            
            if len(recent_alerts) >= self.max_alerts_per_hour:
                self.logger.warning(f"Alert rate limit exceeded. Suppressing alert: {title}")
                return
            
            # Log alert
            alert_record = {
                'timestamp': current_time,
                'level': level,
                'title': title,
                'message': message,
                'data': data
            }
            
            self.alert_history.append(alert_record)
            
            # Console alert
            print(f"\n{'='*60}")
            print(f"ðŸš¨ {level.upper()} ALERT: {title}")
            print(f"Time: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"Message: {message}")
            if data:
                print(f"Data: {json.dumps(data, indent=2)}")
            print(f"{'='*60}\n")
            
            # Log to file
            self.logger.warning(f"ALERT [{level}] {title}: {message}")
            
        except Exception as e:
            self.logger.error(f"Failed to send alert: {e}")

class EnterpriseQualityControlSystem:
    """Enterprise-grade predictive quality control system"""
    
    def __init__(self, config: SystemConfiguration):
        self.config = config
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # Initialize components
        self.db_manager = DatabaseManager(config.db_config)
        self.model_manager = ModelManager(config.model_config, self.db_manager)
        self.data_validator = DataQualityValidator(config.quality_thresholds)
        self.alert_manager = AlertManager(config)
        
        # System state
        self.system_status = SystemStatus.HEALTHY
        self.last_health_check = None
        self.performance_metrics = {}
        
        # Initialize system
        self._initialize_system()
    
    def _initialize_system(self):
        """Initialize system components and perform health checks"""
        try:
            self.logger.info("Initializing Enterprise Quality Control System...")
            
            # Create necessary directories
            os.makedirs('models', exist_ok=True)
            os.makedirs('reports', exist_ok=True)
            os.makedirs('backups', exist_ok=True)
            
            # Initialize database schema
            self._initialize_database_schema()
            
            # Load existing model if available
            self._load_existing_model()
            
            # Perform initial health check
            self.perform_health_check()
            
            self.logger.info("System initialization completed successfully")
            
        except Exception as e:
            self.logger.error(f"System initialization failed: {e}")
            self.system_status = SystemStatus.CRITICAL
            raise
    
    def _initialize_database_schema(self):
        """Initialize complete database schema"""
        schema_sql = [
            # Main data tables
            """
            CREATE SCHEMA IF NOT EXISTS cmp_data;
            """,
            """
            CREATE TABLE IF NOT EXISTS cmp_data.pad_quality (
                id SERIAL PRIMARY KEY,
                batch_id VARCHAR(50) NOT NULL,
                pad_id VARCHAR(50) NOT NULL,
                thickness DECIMAL(10,4),
                pressure DECIMAL(10,4),
                temperature DECIMAL(10,4),
                rotation_speed DECIMAL(10,4),
                is_faulty BOOLEAN NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                ingested_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                data_source VARCHAR(50) DEFAULT 'production',
                quality_score DECIMAL(5,2),
                CONSTRAINT valid_thickness CHECK (thickness BETWEEN 0.1 AND 2.0),
                CONSTRAINT valid_pressure CHECK (pressure BETWEEN 0.1 AND 15.0),
                CONSTRAINT valid_temperature CHECK (temperature BETWEEN 10.0 AND 50.0),
                CONSTRAINT valid_rotation_speed CHECK (rotation_speed BETWEEN 10.0 AND 300.0)
            );
            """,
            """
            CREATE TABLE IF NOT EXISTS cmp_data.defect_predictions (
                id SERIAL PRIMARY KEY,
                pad_id VARCHAR(50),
                defect_probability DECIMAL(8,6),
                risk_level VARCHAR(20),
                recommended_action VARCHAR(100),
                cost_saved DECIMAL(10,2),
                model_version VARCHAR(20),
                model_accuracy DECIMAL(8,6),
                prediction_confidence VARCHAR(50),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            """
            CREATE TABLE IF NOT EXISTS cmp_data.system_health_log (
                id SERIAL PRIMARY KEY,
                system_status VARCHAR(20),
                cpu_usage DECIMAL(5,2),
                memory_usage DECIMAL(5,2),
                disk_usage DECIMAL(5,2),
                database_status VARCHAR(20),
                model_status VARCHAR(20),
                data_quality_score DECIMAL(5,2),
                alerts_count INTEGER,
                performance_metrics JSONB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """
        ]
        
        for sql in schema_sql:
            if not self.db_manager.execute_command(sql):
                raise Exception(f"Failed to execute schema SQL: {sql[:100]}...")
        
        # Create indexes for performance
        index_sql = [
            "CREATE INDEX IF NOT EXISTS idx_pad_quality_created_at ON cmp_data.pad_quality(created_at);",
            "CREATE INDEX IF NOT EXISTS idx_pad_quality_batch_id ON cmp_data.pad_quality(batch_id);",
            "CREATE INDEX IF NOT EXISTS idx_pad_quality_is_faulty ON cmp_data.pad_quality(is_faulty);",
            "CREATE INDEX IF NOT EXISTS idx_defect_predictions_created_at ON cmp_data.defect_predictions(created_at);",
            "CREATE INDEX IF NOT EXISTS idx_system_health_created_at ON cmp_data.system_health_log(created_at);"
        ]
        
        for sql in index_sql:
            self.db_manager.execute_command(sql)
    
    def _load_existing_model(self):
        """Load existing model if available"""
        try:
            if os.path.exists('defect_prediction_model.pkl') and os.path.exists('defect_scaler.pkl'):
                self.model_manager.model = joblib.load('defect_prediction_model.pkl')
                self.model_manager.scaler = joblib.load('defect_scaler.pkl')
                self.logger.info("Existing model loaded successfully")
            else:
                self.logger.info("No existing model found")
        except Exception as e:
            self.logger.warning(f"Could not load existing model: {e}")
    
    def perform_health_check(self) -> Dict[str, Any]:
        """Comprehensive system health check"""
        health_report = {
            'timestamp': datetime.now(),
            'overall_status': SystemStatus.HEALTHY.value,
            'components': {},
            'performance_metrics': {},
            'recommendations': []
        }
        
        try:
            # Database health
            db_status = self._check_database_health()
            health_report['components']['database'] = db_status
            
            # Model health
            model_status = self._check_model_health()
            health_report['components']['model'] = model_status
            
            # Data quality health
            data_status = self._check_data_quality_health()
            health_report['components']['data_quality'] = data_status
            
            # Determine overall status
            component_statuses = [status['status'] for status in health_report['components'].values()]
            
            if any(status == SystemStatus.CRITICAL.value for status in component_statuses):
                health_report['overall_status'] = SystemStatus.CRITICAL.value
            elif any(status == SystemStatus.WARNING.value for status in component_statuses):
                health_report['overall_status'] = SystemStatus.WARNING.value
            
            self.system_status = SystemStatus(health_report['overall_status'])
            self.last_health_check = datetime.now()
            
            return health_report
            
        except Exception as e:
            self.logger.error(f"Health check failed: {e}")
            health_report['overall_status'] = SystemStatus.CRITICAL.value
            health_report['error'] = str(e)
            return health_report
    
    def _check_database_health(self) -> Dict[str, Any]:
        """Check database connectivity and performance"""
        try:
            start_time = time.time()
            
            # Test basic connectivity
            result = self.db_manager.execute_query("SELECT 1 as test")
            if result is None:
                return {'status': SystemStatus.CRITICAL.value, 'message': 'Database connection failed'}
            
            # Check response time
            response_time = time.time() - start_time
            
            # Check record counts
            count_query = "SELECT COUNT(*) as count FROM cmp_data.pad_quality"
            count_result = self.db_manager.execute_query(count_query)
            total_records = count_result.iloc[0]['count'] if count_result is not None else 0
            
            # Recent data check
            recent_query = """
            SELECT COUNT(*) as count FROM cmp_data.pad_quality 
            WHERE created_at >= NOW() - INTERVAL '1 hour'
            """
            recent_result = self.db_manager.execute_query(recent_query)
            recent_records = recent_result.iloc[0]['count'] if recent_result is not None else 0
            
            status = SystemStatus.HEALTHY.value
            issues = []
            
            if response_time > 5.0:
                status = SystemStatus.WARNING.value
                issues.append(f"Slow database response: {response_time:.2f}s")
            
            if recent_records < self.config.quality_thresholds.min_hourly_records:
                status = SystemStatus.WARNING.value
                issues.append(f"Low recent data: {recent_records} records in last hour")
            
            return {
                'status': status,
                'response_time': response_time,
                'total_records': total_records,
                'recent_records': recent_records,
                'issues': issues
            }
            
        except Exception as e:
            return {
                'status': SystemStatus.CRITICAL.value,
                'error': str(e)
            }
    
    def _check_model_health(self) -> Dict[str, Any]:
        """Check ML model status and performance"""
        try:
            if self.model_manager.model is None:
                return {
                    'status': SystemStatus.WARNING.value,
                    'message': 'No model loaded'
                }
            
            # Check model age
            if self.model_manager.last_training_time:
                hours_old = (datetime.now() - self.model_manager.last_training_time).total_seconds() / 3600
            else:
                hours_old = float('inf')
            
            # Check model accuracy
            accuracy = self.model_manager.model_accuracy
            
            status = SystemStatus.HEALTHY.value
            issues = []
            
            if accuracy < self.config.model_config.min_accuracy_threshold:
                status = SystemStatus.WARNING.value
                issues.append(f"Low model accuracy: {accuracy:.3f}")
            
            if hours_old > self.config.model_config.retrain_frequency_hours * 2:
                status = SystemStatus.WARNING.value
                issues.append(f"Model outdated: {hours_old:.1f} hours old")
            
            return {
                'status': status,
                'accuracy': accuracy,
                'hours_old': hours_old,
                'version': self.model_manager.model_version,
                'issues': issues
            }
            
        except Exception as e:
            return {
                'status': SystemStatus.CRITICAL.value,
                'error': str(e)
            }
    
    def _check_data_quality_health(self) -> Dict[str, Any]:
        """Check recent data quality"""
        try:
            # Get recent data
            query = """
            SELECT * FROM cmp_data.pad_quality 
            WHERE created_at >= NOW() - INTERVAL '2 hours'
            """
            
            df = self.db_manager.execute_query(query)
            
            if df is None or len(df) == 0:
                return {
                    'status': SystemStatus.WARNING.value,
                    'message': 'No recent data available'
                }
            
            # Validate data quality
            is_valid, validation_report = self.data_validator.validate_batch_data(df)
            
            # Calculate fault rate
            fault_rate = (df['is_faulty'].sum() / len(df)) * 100
            
            status = SystemStatus.HEALTHY.value
            issues = validation_report['issues']
            
            if fault_rate > self.config.quality_thresholds.fault_rate_critical:
                status = SystemStatus.CRITICAL.value
                issues.append(f"Critical fault rate: {fault_rate:.1f}%")
            elif fault_rate > self.config.quality_thresholds.fault_rate_warning:
                status = SystemStatus.WARNING.value
                issues.append(f"High fault rate: {fault_rate:.1f}%")
            
            if not is_valid:
                status = SystemStatus.WARNING.value
            
            return {
                'status': status,
                'fault_rate': fault_rate,
                'data_quality_score': 100 - len(issues) * 10,  # Simple scoring
                'total_records': len(df),
                'issues': issues
            }
            
        except Exception as e:
            return {
                'status': SystemStatus.CRITICAL.value,
                'error': str(e)
            }
    
    def run_continuous_learning_pipeline(self) -> bool:
        """Execute the complete continuous learning pipeline"""
        pipeline_start_time = time.time()
        
        try:
            self.logger.info("Starting continuous learning pipeline...")
            
            # Step 1: Health check
            self.logger.info("Step 1: Performing system health check...")
            health_report = self.perform_health_check()
            
            if health_report['overall_status'] == SystemStatus.CRITICAL.value:
                self.alert_manager.send_alert(
                    'CRITICAL', 
                    'System Health Check Failed',
                    f"Critical system issues detected: {health_report}",
                    health_report
                )
                return False
            
            # Step 2: Data quality monitoring
            self.logger.info("Step 2: Monitoring data quality...")
            self._monitor_data_quality()
            
            # Step 3: Model management
            self.logger.info("Step 3: Checking model status...")
            should_retrain, reason = self.model_manager.should_retrain_model()
            
            if should_retrain:
                self.logger.info(f"Retraining model: {reason}")
                success, training_report = self.model_manager.train_model()
                
                if success:
                    self.logger.info(f"Model retrained successfully - Accuracy: {training_report['accuracy']:.3f}")
                else:
                    self.alert_manager.send_alert(
                        'WARNING',
                        'Model Training Failed',
                        f"Model retraining failed: {training_report['issues']}",
                        training_report
                    )
            else:
                self.logger.info(f"Model is current: {reason}")
            
            # Step 4: Predictive analysis
            self.logger.info("Step 4: Running predictive analysis...")
            self._run_predictive_analysis()
            
            # Step 5: Generate comprehensive report
            self.logger.info("Step 5: Generating system report...")
            self._generate_comprehensive_report()
            
            pipeline_duration = time.time() - pipeline_start_time
            self.logger.info(f"Pipeline completed successfully in {pipeline_duration:.2f} seconds")
            
            return True
            
        except Exception as e:
            self.logger.error(f"Pipeline execution failed: {e}")
            self.alert_manager.send_alert(
                'CRITICAL',
                'Pipeline Execution Failed',
                f"Continuous learning pipeline failed: {str(e)}"
            )
            return False
    
    def _monitor_data_quality(self):
        """Monitor and report data quality issues"""
        try:
            # Get recent data
            query = """
            SELECT * FROM cmp_data.pad_quality 
            WHERE created_at >= NOW() - INTERVAL '1 hour'
            ORDER BY created_at DESC
            """
            
            df = self.db_manager.execute_query(query)
            
            if df is None or len(df) == 0:
                self.alert_manager.send_alert(
                    'WARNING',
                    'No Recent Data',
                    'No production data received in the last hour'
                )
                return
            
            # Validate data quality
            is_valid, validation_report = self.data_validator.validate_batch_data(df)
            
            # Check for quality issues
            if not is_valid:
                self.alert_manager.send_alert(
                    'WARNING',
                    'Data Quality Issues Detected',
                    f"Data quality problems: {validation_report['issues']}",
                    validation_report
                )
            
            # Check fault rate
            fault_rate = (df['is_faulty'].sum() / len(df)) * 100
            
            if fault_rate > self.config.quality_thresholds.fault_rate_critical:
                self.alert_manager.send_alert(
                    'CRITICAL',
                    'Critical Fault Rate',
                    f'Fault rate {fault_rate:.1f}% exceeds critical threshold {self.config.quality_thresholds.fault_rate_critical}%',
                    {'fault_rate': fault_rate, 'threshold': self.config.quality_thresholds.fault_rate_critical}
                )
            elif fault_rate > self.config.quality_thresholds.fault_rate_warning:
                self.alert_manager.send_alert(
                    'WARNING',
                    'High Fault Rate',
                    f'Fault rate {fault_rate:.1f}% exceeds warning threshold {self.config.quality_thresholds.fault_rate_warning}%',
                    {'fault_rate': fault_rate, 'threshold': self.config.quality_thresholds.fault_rate_warning}
                )
            
            self.logger.info(f"Data quality monitoring completed - {len(df)} records, {fault_rate:.1f}% fault rate")
            
        except Exception as e:
            self.logger.error(f"Data quality monitoring failed: {e}")
    
    def _run_predictive_analysis(self):
        """Run predictive analysis on recent production data"""
        try:
            if self.model_manager.model is None:
                self.logger.warning("No model available for predictive analysis")
                return
            
            # Get recent production data
            query = """
            SELECT pad_id, thickness, pressure, temperature, rotation_speed, created_at
            FROM cmp_data.pad_quality
            WHERE created_at >= NOW() - INTERVAL '30 minutes'
            ORDER BY created_at DESC
            """
            
            df = self.db_manager.execute_query(query)
            
            if df is None or len(df) == 0:
                self.logger.info("No recent production data for predictive analysis")
                return
            
            predictions = []
            total_cost_saved = 0
            high_risk_count = 0
            
            for _, row in df.iterrows():
                # Get prediction
                prediction, defect_prob, confidence = self.model_manager.predict_defect_probability(
                    row['thickness'], row['pressure'], row['temperature'], row['rotation_speed']
                )
                
                if prediction is None:
                    continue
                
                # Risk assessment
                if defect_prob >= 0.8:
                    risk_level = RiskLevel.CRITICAL
                    action = "STOP PRODUCTION - IMMEDIATE DISCARD"
                    cost_saved = self.config.cost_per_defect - self.config.cost_per_early_discard
                    high_risk_count += 1
                elif defect_prob >= 0.7:
                    risk_level = RiskLevel.HIGH
                    action = "DISCARD IMMEDIATELY"
                    cost_saved = self.config.cost_per_defect - self.config.cost_per_early_discard
                    high_risk_count += 1
                elif defect_prob >= 0.5:
                    risk_level = RiskLevel.MEDIUM
                    action = "REWORK RECOMMENDED"
                    cost_saved = self.config.cost_per_defect * 0.6
                elif defect_prob >= 0.3:
                    risk_level = RiskLevel.ELEVATED
                    action = "MONITOR CLOSELY"
                    cost_saved = 0
                else:
                    risk_level = RiskLevel.LOW
                    action = "CONTINUE PRODUCTION"
                    cost_saved = 0
                
                total_cost_saved += cost_saved
                
                predictions.append({
                    'pad_id': row['pad_id'],
                    'defect_probability': defect_prob,
                    'risk_level': risk_level.value,
                    'recommended_action': action,
                    'cost_saved': cost_saved,
                    'confidence': confidence,
                    'timestamp': row['created_at']
                })
            
            # Store predictions
            self._store_predictions(predictions)
            
            # Generate alerts for high-risk situations
            if high_risk_count > 0:
                self.alert_manager.send_alert(
                    'CRITICAL' if high_risk_count > 3 else 'WARNING',
                    'High-Risk Pads Detected',
                    f'{high_risk_count} high-risk pads detected in last 30 minutes. Potential cost savings: ${total_cost_saved:.2f}',
                    {
                        'high_risk_count': high_risk_count,
                        'total_predictions': len(predictions),
                        'total_cost_saved': total_cost_saved
                    }
                )
            
            self.logger.info(f"Predictive analysis completed - {len(predictions)} predictions, {high_risk_count} high-risk, ${total_cost_saved:.2f} potential savings")
            
        except Exception as e:
            self.logger.error(f"Predictive analysis failed: {e}")
    
    def _store_predictions(self, predictions: List[Dict[str, Any]]):
        """Store predictions in database"""
        try:
            for prediction in predictions:
                sql = """
                INSERT INTO cmp_data.defect_predictions 
                (pad_id, defect_probability, risk_level, recommended_action, cost_saved, 
                 model_version, model_accuracy, prediction_confidence)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                """
                
                params = (
                    prediction['pad_id'],
                    prediction['defect_probability'],
                    prediction['risk_level'],
                    prediction['recommended_action'],
                    prediction['cost_saved'],
                    self.model_manager.model_version,
                    self.model_manager.model_accuracy,
                    prediction['confidence']
                )
                
                self.db_manager.execute_command(sql, params)
            
            self.logger.info(f"Stored {len(predictions)} predictions in database")
            
        except Exception as e:
            self.logger.error(f"Failed to store predictions: {e}")
    
    def _generate_comprehensive_report(self):
        """Generate comprehensive system and quality report"""
        try:
            report_timestamp = datetime.now()
            
            # Get system metrics
            health_report = self.perform_health_check()
            
            # Get production metrics
            production_metrics = self._get_production_metrics()
            
            # Get prediction metrics
            prediction_metrics = self._get_prediction_metrics()
            
            # Generate report
            report = f"""
            ===============================================
            CMP PREDICTIVE QUALITY CONTROL SYSTEM REPORT
            Generated: {report_timestamp.strftime('%Y-%m-%d %H:%M:%S')}
            ===============================================
            
            SYSTEM STATUS: {health_report['overall_status']}
            
            PRODUCTION METRICS (Last 24 Hours):
            - Total Records: {production_metrics.get('total_records', 0)}
            - Fault Rate: {production_metrics.get('fault_rate', 0):.2f}%
            - Average Thickness: {production_metrics.get('avg_thickness', 0):.4f} mm
            - Average Pressure: {production_metrics.get('avg_pressure', 0):.4f} psi
            - Average Temperature: {production_metrics.get('avg_temperature', 0):.4f} Â°C
            - Average Rotation Speed: {production_metrics.get('avg_rotation_speed', 0):.4f} RPM
            
            PREDICTIVE ANALYTICS (Last 24 Hours):
            - Total Predictions: {prediction_metrics.get('total_predictions', 0)}
            - High Risk Detections: {prediction_metrics.get('high_risk_count', 0)}
            - Medium Risk Detections: {prediction_metrics.get('medium_risk_count', 0)}
            - Total Cost Savings: ${prediction_metrics.get('total_cost_saved', 0):.2f}
            - Model Accuracy: {self.model_manager.model_accuracy:.3f}
            - Model Version: {self.model_manager.model_version}
            
            COMPONENT STATUS:
            - Database: {health_report['components']['database']['status']}
            - ML Model: {health_report['components']['model']['status']}
            - Data Quality: {health_report['components']['data_quality']['status']}
            
            RECOMMENDATIONS:
            """
            
            # Add recommendations based on metrics
            if production_metrics.get('fault_rate', 0) > self.config.quality_thresholds.fault_rate_warning:
                report += "\n            ðŸš¨ HIGH FAULT RATE: Investigate production parameters"
            
            if prediction_metrics.get('high_risk_count', 0) > 5:
                report += "\n            âš ï¸  FREQUENT HIGH-RISK DETECTIONS: Review process control"
            
            if self.model_manager.model_accuracy < 0.85:
                report += "\n            ðŸ¤– MODEL PERFORMANCE: Consider retraining with more data"
            
            report += f"\n            ===============================================\n"
            
            # Save report
            report_filename = f"reports/comprehensive_report_{report_timestamp.strftime('%Y%m%d_%H%M%S')}.txt"
            
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write(report)
            
            # Display key metrics
            print(report)
            
            self.logger.info(f"Comprehensive report generated: {report_filename}")
            
        except Exception as e:
            self.logger.error(f"Failed to generate comprehensive report: {e}")
    
    def _get_production_metrics(self) -> Dict[str, Any]:
        """Get production metrics for reporting"""
        try:
            query = """
            SELECT 
                COUNT(*) as total_records,
                COUNT(CASE WHEN is_faulty = true THEN 1 END) * 100.0 / COUNT(*) as fault_rate,
                AVG(thickness) as avg_thickness,
                AVG(pressure) as avg_pressure,
                AVG(temperature) as avg_temperature,
                AVG(rotation_speed) as avg_rotation_speed
            FROM cmp_data.pad_quality
            WHERE created_at >= NOW() - INTERVAL '24 hours'
            """
            
            result = self.db_manager.execute_query(query)
            
            if result is not None and len(result) > 0:
                return result.iloc[0].to_dict()
            else:
                return {}
                
        except Exception as e:
            self.logger.error(f"Failed to get production metrics: {e}")
            return {}
    
    def _get_prediction_metrics(self) -> Dict[str, Any]:
        """Get prediction metrics for reporting"""
        try:
            query = """
            SELECT 
                COUNT(*) as total_predictions,
                COUNT(CASE WHEN risk_level LIKE '%HIGH%' OR risk_level LIKE '%CRITICAL%' THEN 1 END) as high_risk_count,
                COUNT(CASE WHEN risk_level LIKE '%MEDIUM%' THEN 1 END) as medium_risk_count,
                SUM(cost_saved) as total_cost_saved
            FROM cmp_data.defect_predictions
            WHERE created_at >= NOW() - INTERVAL '24 hours'
            """
            
            result = self.db_manager.execute_query(query)
            
            if result is not None and len(result) > 0:
                return result.iloc[0].to_dict()
            else:
                return {}
                
        except Exception as e:
            self.logger.error(f"Failed to get prediction metrics: {e}")
            return {}

class EnhancedPipelineOrchestrator:
    """Main orchestrator for the enhanced pipeline"""
    
    def __init__(self):
        # Configuration
        self.config = SystemConfiguration(
            db_config={
                'host': 'localhost',
                'database': 'cmp_warehouse',
                'user': 'airflow',
                'password': 'airflow',
                'port': '5432'
            },
            quality_thresholds=QualityThresholds(),
            model_config=ModelConfiguration()
        )
        
        # Initialize quality control system
        self.quality_system = EnterpriseQualityControlSystem(self.config)
        
        # Setup logging
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
    
    def run_data_generation(self) -> bool:
        """Run data generation with validation"""
        try:
            self.logger.info("Running data generation...")
            
            result = subprocess.run(
                ['python', 'simple_producer.py'], 
                capture_output=True, text=True, timeout=60
            )
            
            if result.returncode == 0:
                self.logger.info("Data generation completed successfully")
                return True
            else:
                self.logger.error(f"Data generation failed: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            self.logger.error("Data generation timed out")
            return False
        except Exception as e:
            self.logger.error(f"Data generation error: {e}")
            return False
    
    def run_data_processing(self) -> bool:
        """Run data processing with validation"""
        try:
            self.logger.info("Running data processing...")
            
            result = subprocess.run(
                ['python', 'simple_consumer.py'], 
                capture_output=True, text=True, timeout=60
            )
            
            if result.returncode == 0:
                self.logger.info("Data processing completed successfully")
                return True
            else:
                self.logger.error(f"Data processing failed: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            self.logger.error("Data processing timed out")
            return False
        except Exception as e:
            self.logger.error(f"Data processing error: {e}")
            return False
    
    def run_complete_pipeline(self) -> bool:
        """Execute the complete enhanced pipeline"""
        pipeline_start_time = time.time()
        
        self.logger.info("="*70)
        self.logger.info(f"STARTING ENHANCED CMP PIPELINE - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info("="*70)
        
        try:
            # Step 1: Data generation
            if not self.run_data_generation():
                return False
            
            # Step 2: Data processing
            if not self.run_data_processing():
                return False
            
            # Step 3: Wait for data to settle
            time.sleep(3)
            
            # Step 4: Run quality control pipeline
            if not self.quality_system.run_continuous_learning_pipeline():
                return False
            
            pipeline_duration = time.time() - pipeline_start_time
            
            self.logger.info("="*70)
            self.logger.info(f"PIPELINE COMPLETED SUCCESSFULLY - Duration: {pipeline_duration:.2f}s")
            self.logger.info("="*70)
            
            return True
            
        except Exception as e:
            self.logger.error(f"Pipeline execution failed: {e}")
            return False

def main():
    """Main execution function"""
    print("ðŸ­ Enterprise CMP Predictive Quality Control System")
    print("=" * 70)
    print("ðŸ¤– AI-Powered Continuous Learning")
    print("ðŸ“Š Industrial-Grade Data Quality Monitoring")
    print("ðŸ”„ Automated Model Management")
    print("ðŸš¨ Real-time Alert System")
    print("ðŸ’° Cost-Optimized Defect Prevention")
    print("=" * 70)
    
    # Create orchestrator
    orchestrator = EnhancedPipelineOrchestrator()
    
    try:
        # Run initial pipeline
        print("ðŸ”„ Running initial pipeline execution...")
        orchestrator.run_complete_pipeline()
        
        # Schedule pipeline
        schedule.every(15).minutes.do(orchestrator.run_complete_pipeline)
        
        print("ðŸ“… Enhanced pipeline scheduled every 15 minutes")
        print("ðŸ¤– Continuous learning and adaptation enabled")
        print("ðŸ” Real-time monitoring and alerting active")
        print("ðŸ’¡ Press Ctrl+C to stop the system")
        print("=" * 70)
        
        # Main execution loop
        while True:
            schedule.run_pending()
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\n" + "=" * 70)
        print("ðŸ‘‹ Enterprise CMP Predictive Quality Control System stopped.")
        print("ðŸ¤– All models and data saved successfully.")
        print("ðŸ“Š Monitoring logs and reports available in respective directories.")
        print("ðŸ”„ System ready to resume operations.")
        print("=" * 70)
    except Exception as e:
        logging.error(f"System error: {e}")
        print(f"âŒ System error: {e}")

if __name__ == '__main__':
    main()